{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MNIST contains 70,000 images of handwritten digits: 60,000 for training and 10,000 for testing. The images are grayscale, 28x28 pixels, and centered to reduce preprocessing and get started quicker.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-03-data'\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "    tar.extractall(path=data_base_path)\n",
    "    \n",
    "    \n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_data(filename, image_shape, image_number):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(np.prod(image_shape) * image_number)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(image_number, image_shape[0], image_shape[1])\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, image_number):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * image_number)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels\n",
    "\n",
    "image_shape = (28, 28)\n",
    "train_set_size = 60000\n",
    "test_set_size = 10000\n",
    "\n",
    "data_part2_folder = os.path.join(data_base_path, data_folder, 'part2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTdataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        # Initialize data, download, etc.\n",
    "        # read with numpy or pandas\n",
    "        \n",
    "        train_images_path = os.path.join(data_part2_folder, 'train-images-idx3-ubyte.gz')\n",
    "        train_labels_path = os.path.join(data_part2_folder, 'train-labels-idx1-ubyte.gz')\n",
    "        #test_images_path = os.path.join(data_part2_folder, 't10k-images-idx3-ubyte.gz')\n",
    "        #test_labels_path = os.path.join(data_part2_folder, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "        train_images = extract_data(train_images_path, image_shape, train_set_size)\n",
    "        train_labels = extract_labels(train_labels_path, train_set_size)\n",
    "        #test_images = extract_data(test_images_path, image_shape, test_set_size)\n",
    "        #test_labels = extract_labels(test_labels_path, test_set_size)\n",
    "\n",
    "        self.train_input = torch.from_numpy(train_images.reshape(train_images.shape[0], 1, train_images.shape[1], train_images.shape[2]))\n",
    "        self.train_target = torch.from_numpy(train_labels)        \n",
    "        #self.test_input = torch.from_numpy(test_images.reshape(test_images.shape[0], 1, test_images.shape[1], test_images.shape[2]))\n",
    "        #self.test_target = torch.from_numpy(test_labels)\n",
    "                \n",
    "        self.nb_samples = train_images.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.train_input[index], self.train_target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.nb_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNISTdataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   3.,  18.,  18.,  18., 126., 136., 175.,  26., 166., 255.,\n",
       "           247., 127.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  30.,  36.,  94.,\n",
       "           154., 170., 253., 253., 253., 253., 253., 225., 172., 253., 242.,\n",
       "           195.,  64.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253.,\n",
       "           253., 253., 253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,\n",
       "            39.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  18., 219., 253., 253.,\n",
       "           253., 253., 253., 198., 182., 247., 241.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107.,\n",
       "           253., 253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  14.,   1.,\n",
       "           154., 253.,  90.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            11., 190., 253.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,  81., 240., 253., 253., 119.,  25.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,  16.,  93., 252., 253., 187.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0., 249., 253., 249.,  64.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,  39., 148., 229., 253., 253., 253., 250., 182.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24.,\n",
       "           114., 221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  23.,  66., 213.,\n",
       "           253., 253., 253., 253., 198.,  81.,   2.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n",
       "           253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,  55., 172., 226., 253., 253., 253., 253.,\n",
       "           244., 133.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135., 132.,\n",
       "            16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "             0.,   0.,   0.,   0.,   0.,   0.]]]), tensor(5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = dataset[0]\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([[[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   3.,  18.,  18.,  18., 126., 136., 175.,  26., 166., 255.,\n",
      "          247., 127.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  30.,  36.,  94.,\n",
      "          154., 170., 253., 253., 253., 253., 253., 225., 172., 253., 242.,\n",
      "          195.,  64.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253.,\n",
      "          253., 253., 253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,\n",
      "           39.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  18., 219., 253., 253.,\n",
      "          253., 253., 253., 198., 182., 247., 241.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107.,\n",
      "          253., 253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  14.,   1.,\n",
      "          154., 253.,  90.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           11., 190., 253.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,  81., 240., 253., 253., 119.,  25.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,  16.,  93., 252., 253., 187.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0., 249., 253., 249.,  64.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,  39., 148., 229., 253., 253., 253., 250., 182.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24.,\n",
      "          114., 221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  23.,  66., 213.,\n",
      "          253., 253., 253., 253., 198.,  81.,   2.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n",
      "          253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,  55., 172., 226., 253., 253., 253., 253.,\n",
      "          244., 133.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135., 132.,\n",
      "           16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.]]])\n",
      "LABELS: tensor(5)\n"
     ]
    }
   ],
   "source": [
    "print('features:',features)\n",
    "print('LABELS:', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.RandomRotation((0,360)),\n",
    "    torchvision.transforms.RandomResizedCrop(28),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size = 500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = MNISTdataset(transform=torchvision.transforms.RandomHorizontalFlip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([[[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   3.,  18.,  18.,  18., 126., 136., 175.,  26., 166., 255.,\n",
      "          247., 127.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  30.,  36.,  94.,\n",
      "          154., 170., 253., 253., 253., 253., 253., 225., 172., 253., 242.,\n",
      "          195.,  64.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253.,\n",
      "          253., 253., 253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,\n",
      "           39.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  18., 219., 253., 253.,\n",
      "          253., 253., 253., 198., 182., 247., 241.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107.,\n",
      "          253., 253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  14.,   1.,\n",
      "          154., 253.,  90.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           11., 190., 253.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,  81., 240., 253., 253., 119.,  25.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,  16.,  93., 252., 253., 187.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0., 249., 253., 249.,  64.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,  39., 148., 229., 253., 253., 253., 250., 182.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24.,\n",
      "          114., 221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  23.,  66., 213.,\n",
      "          253., 253., 253., 253., 198.,  81.,   2.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n",
      "          253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,  55., 172., 226., 253., 253., 253., 253.,\n",
      "          244., 133.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135., 132.,\n",
      "           16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.]]]) tensor(5)\n"
     ]
    }
   ],
   "source": [
    "first_data = dataset2[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "LABELS: tensor([1, 1, 6, 3, 7, 0, 7, 0, 9, 2, 9, 0, 8, 9, 5, 9, 7, 3, 8, 5, 2, 4, 7, 0,\n",
      "        9, 8, 1, 3, 9, 3, 6, 1, 4, 1, 1, 2, 2, 6, 6, 2, 3, 6, 3, 1, 6, 3, 5, 1,\n",
      "        1, 5, 8, 7, 0, 1, 2, 4, 4, 7, 3, 0, 5, 6, 9, 8, 9, 4, 6, 3, 3, 8, 1, 1,\n",
      "        5, 3, 1, 4, 6, 3, 7, 9, 4, 7, 4, 0, 8, 9, 7, 5, 0, 3, 5, 5, 4, 4, 8, 6,\n",
      "        1, 7, 5, 2, 6, 3, 9, 5, 5, 6, 8, 7, 6, 5, 2, 5, 8, 3, 5, 8, 4, 1, 4, 8,\n",
      "        4, 2, 0, 3, 1, 0, 8, 5, 4, 5, 4, 0, 1, 7, 1, 8, 5, 2, 2, 7, 8, 3, 1, 4,\n",
      "        5, 2, 6, 8, 3, 2, 5, 4, 7, 1, 7, 5, 4, 5, 4, 4, 8, 2, 9, 3, 7, 3, 7, 5,\n",
      "        1, 2, 1, 3, 3, 7, 5, 1, 1, 5, 1, 6, 3, 5, 2, 6, 9, 8, 9, 3, 4, 9, 2, 7,\n",
      "        1, 0, 8, 1, 9, 5, 0, 5, 6, 7, 5, 3, 5, 3, 3, 0, 2, 4, 3, 8, 6, 5, 9, 1,\n",
      "        8, 7, 4, 7, 3, 1, 1, 1, 4, 0, 2, 2, 3, 6, 7, 4, 2, 7, 7, 1, 9, 2, 4, 1,\n",
      "        0, 1, 4, 1, 6, 8, 4, 7, 6, 6, 1, 2, 6, 2, 5, 9, 9, 7, 6, 3, 2, 7, 9, 2,\n",
      "        8, 7, 5, 6, 2, 2, 3, 5, 3, 6, 1, 3, 4, 5, 6, 0, 7, 1, 2, 7, 2, 2, 1, 4,\n",
      "        5, 4, 7, 9, 2, 7, 6, 6, 0, 4, 0, 9, 8, 3, 4, 8, 4, 6, 6, 2, 3, 0, 0, 9,\n",
      "        8, 7, 6, 1, 4, 8, 1, 2, 6, 8, 3, 5, 3, 3, 3, 5, 7, 4, 3, 4, 7, 1, 5, 4,\n",
      "        1, 6, 5, 1, 3, 4, 3, 2, 7, 0, 6, 3, 6, 2, 0, 3, 5, 5, 0, 0, 1, 1, 9, 3,\n",
      "        6, 8, 3, 4, 1, 4, 6, 5, 2, 3, 7, 6, 0, 7, 5, 5, 5, 8, 6, 7, 5, 9, 0, 5,\n",
      "        6, 4, 3, 7, 9, 7, 6, 2, 1, 7, 1, 8, 8, 5, 8, 7, 5, 2, 4, 2, 9, 2, 9, 5,\n",
      "        3, 6, 3, 0, 4, 9, 3, 3, 5, 9, 1, 8, 6, 0, 8, 9, 2, 4, 4, 2, 7, 4, 9, 0,\n",
      "        8, 6, 7, 6, 2, 1, 0, 4, 8, 0, 2, 0, 0, 8, 0, 7, 3, 7, 8, 9, 6, 3, 0, 2,\n",
      "        3, 7, 6, 7, 2, 1, 7, 6, 7, 5, 7, 2, 9, 3, 7, 5, 0, 3, 0, 0, 8, 5, 6, 3,\n",
      "        6, 8, 8, 9, 4, 8, 0, 6, 0, 3, 4, 5, 6, 0, 5, 9, 0, 7, 4, 0])\n"
     ]
    }
   ],
   "source": [
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print('features:',features)\n",
    "print('LABELS:', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 15000\n",
      "Epoch: 1/2, Step 5/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 10/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 15/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 20/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 25/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 30/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 35/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 40/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 45/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 50/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 55/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 60/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 65/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 70/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 75/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 80/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 85/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 90/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 95/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 100/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 105/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 110/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 115/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 1/2, Step 120/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 5/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 10/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 15/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 20/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 25/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 30/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 35/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 40/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 45/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 50/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 55/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 60/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 65/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 70/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 75/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 80/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 85/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 90/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 95/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 100/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 105/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 110/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 115/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n",
      "Epoch: 2/2, Step 120/15000| Inputs torch.Size([500, 1, 28, 28]) | Labels torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
    "        # Run your training process\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25 #3\n",
    "batch_size_train = 500 #64\n",
    "batch_size_test = 1000\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "#torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.RandomRotation((0,360)),\n",
    "    torchvision.transforms.RandomResizedCrop(28),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    torchvision.transforms.ToTensor()])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                   torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('data/training', train=True, download=True,\n",
    "                                            transform=train_transforms),\n",
    "                                            batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('data/test', train=False, download=True,\n",
    "                                             transform=test_transforms),\n",
    "                                             batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in (train_loader):\n",
    "    data, target = Variable(data), Variable(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            #torch.save(network.state_dict(), 'results/model.pth')\n",
    "            #torch.save(optimizer.state_dict(), 'results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = network(example_data)\n",
    "    \n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Define a transform to augment the dataset + normalize it\n",
    "train_transform = transforms.Compose([transforms.RandomRotation((0,360)),\n",
    "                                      transforms.RandomResizedCrop(28),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.5,],[0.5,])])\n",
    "                                      #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5,],[0.5,])])\n",
    "\n",
    "train_data = datasets.MNIST('data/training', train=True, download=True, transform=train_transform)\n",
    "test_data = datasets.MNIST('data/test', train=False, download=True, transform=test_transform)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_data.train_labels\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fig, axes = plt.subplots(4, 6, figsize=(24,16))\n",
    "ax = axes.ravel()\n",
    "\n",
    "for ind in range(b.shape[0]):\n",
    "    \n",
    "    ax[2*ind].imshow(test_input[a[ind],0], cmap='gray')\n",
    "    ax[2*ind].axis('off')\n",
    "    \n",
    "    width = 0.75\n",
    "    xpos = np.arange(b.shape[1])  # the x locations for the groups\n",
    "    ax[2*ind+1].barh(xpos, b[ind], width, color=\"blue\")\n",
    "    ax[2*ind+1].set_yticks(xpos)\n",
    "    ax[2*ind+1].set_yticklabels(xpos)\n",
    "    ax[2*ind+1].set_xlim(0,1)\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
